{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 a)\n",
    " Import the libraries that we'll use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy  import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from IPython.display import display, HTML, display_pretty\n",
    "np.random.seed(101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write all the functions that we'll need\n",
    "\n",
    " For failure simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def failures(H):\n",
    "    '''\n",
    "     Simulate failures in the graph H.\n",
    "     Return S = list with size of largest component. This is a fraction of the total\n",
    "     number of nodes\n",
    "     Return vn = list with fraction of removed nodes\n",
    "\n",
    "    '''\n",
    "    G = H.copy()\n",
    "    from random import choice\n",
    "    N0 = len(G)\n",
    "    minComponentSize = int(0.01*N0)\n",
    "    if minComponentSize < 1:\n",
    "        minComponentSize = 1\n",
    "    vn = []\n",
    "    S = []\n",
    "    n = 0 #number of nodes removed\n",
    "    while(len(G.nodes()) > minComponentSize):\n",
    "        #print('Removing... n = ', n)\n",
    "        #print(G.nodes)\n",
    "        node = random.choice(G.nodes()) #select the node on the largest component\n",
    "        #print('selected to removed:', node)\n",
    "        G.remove_node(node)\n",
    "        Gcc=sorted(nx.connected_component_subgraphs(G), key = len, reverse=True)\n",
    "        Glc=Gcc[0]\n",
    "        S.append(len(Glc)/N0) #store the size of the largest component\n",
    "        n = n + 1\n",
    "        vn.append(n/N0)\n",
    "    return S, vn\n",
    "\n",
    "def most_connected(G): # This function is used to find the most connected node\n",
    "    maxk = 0\n",
    "    node = 0\n",
    "    for i in G.nodes():\n",
    "        if(G.degree(i) >= maxk):\n",
    "            maxk = G.degree(i)\n",
    "            node = i\n",
    "    return node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For attack simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attacks(H):\n",
    "    '''\n",
    "     Simulate attacks in the graph H.\n",
    "     Return S = list with size of largest component. This is a fraction of the total\n",
    "     number of nodes\n",
    "     Return vn = list with fraction of removed nodes\n",
    "    '''\n",
    "    G = H.copy()\n",
    "    from random import choice\n",
    "    N0 = len(G)\n",
    "    minComponentSize = int(0.01*N0)\n",
    "    if minComponentSize < 1:\n",
    "        minComponentSize = 1\n",
    "    vn = []\n",
    "    S = []\n",
    "    n = 0 #number of nodes removed\n",
    "    while(len(G.nodes()) > minComponentSize):\n",
    "        #print('Removing... n = ', n)\n",
    "        #print(G.nodes)\n",
    "        node = most_connected(G) #select the most connected node on the largest component\n",
    "        #print('selected to removed:', node)\n",
    "        G.remove_node(node)\n",
    "        Gcc=sorted(nx.connected_component_subgraphs(G), key = len, reverse=True)\n",
    "        Glc=Gcc[0]\n",
    "        S.append(len(Glc)/N0) #store the size of the largest component\n",
    "        n = n + 1\n",
    "        vn.append(n/N0)\n",
    "    return S, vn\n",
    "\n",
    "\n",
    "def fcritical(G):\n",
    "    '''\n",
    "        Calculate critical fraction of nodes that needs to be removed in order to\n",
    "        break an heterogeneous network G.\n",
    "    '''\n",
    "    def momment_of_degree_distribution2(G,m):\n",
    "        M = 0\n",
    "        N = len(G)\n",
    "        for i in G.nodes():\n",
    "            M = M + G.degree(i)**m\n",
    "        M = M/N\n",
    "        return M\n",
    "    f = 1 - 1/(momment_of_degree_distribution2(G,2)/momment_of_degree_distribution2(G,1) - 1)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Arguments to create the network\n",
    "    N = 200\n",
    "    av_degree = 2\n",
    "    p = av_degree/(N-1)\n",
    "    m = int(av_degree/2)\n",
    "\n",
    "    # Create a list with the networks\n",
    "    networks = []\n",
    "    networks.append(nx.gnp_random_graph(N, p, seed=42, directed=False))\n",
    "    networks[-1].name = 'ER'\n",
    "    networks.append(nx.barabasi_albert_graph(N, m, seed=42))\n",
    "    networks[-1].name = 'BA'\n",
    "    networks.append(nx.watts_strogatz_graph(N, av_degree, 0.001, seed=42))\n",
    "    networks[-1].name = 'WS0.001'\n",
    "    networks.append(nx.watts_strogatz_graph(N, av_degree, 0.01, seed=42))\n",
    "    networks[-1].name = 'WS0.01'\n",
    "    networks.append(nx.watts_strogatz_graph(N, av_degree, 0.1, seed=42))\n",
    "    networks[-1].name = 'WS0.1'\n",
    "\n",
    "\n",
    "    # Calculate the response to failures of all the networks inside list networks\n",
    "    results = []\n",
    "    currentNetworkSimulations = []\n",
    "    nSimulations = 2\n",
    "    removedNodes = None\n",
    "    for i in range(len(networks)):\n",
    "        # Do simulations and append them to currentNetworkSimulations\n",
    "        for j in range(nSimulations):\n",
    "            if (i == 0) and (j == 0):\n",
    "                componentSize, removedNodes = failures(networks[i])\n",
    "            else:\n",
    "                componentSize, _ = failures(networks[i])\n",
    "            currentNetworkSimulations.append(componentSize)\n",
    "\n",
    "\n",
    "        # Calculate the average of the simulations\n",
    "        averageOfSimulations = []\n",
    "        for j in range(len(currentNetworkSimulations[0])):\n",
    "            partialSum = 0\n",
    "            for simulation in currentNetworkSimulations:\n",
    "                partialSum += simulation[j]\n",
    "            #print(partialSum/len(currentNetworkSimulations))\n",
    "            averageOfSimulations.append(partialSum/len(currentNetworkSimulations))\n",
    "\n",
    "        # Append averageOfSimulations to results\n",
    "        results.append(averageOfSimulations)\n",
    "\n",
    "        # Clear list\n",
    "        currentNetworkSimulations.clear()\n",
    "\n",
    "    plt.figure()\n",
    "    # Plot all results of simulation\n",
    "    for i in range(len(results)):\n",
    "        plt.plot(removedNodes, results[i], '-o', label=networks[i].name)\n",
    "    plt.title('Failure Comparison')\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"f\", fontsize=20)\n",
    "    plt.ylabel(\"S\", fontsize=20)\n",
    "    plt.grid(True)\n",
    "    # Save figure\n",
    "    plt.savefig('lastPlotEx1a.png')\n",
    "    plt.show(block=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot we can clearly see that the more scale-free a network is, the more resilient to failures it becomes.\n",
    "\n",
    " The BA network has a power law degree distribution and is more robust to failures than the random graph of ER that has poisson degree distribution.\n",
    "\n",
    " This happens because the probability of a failure in a hub to occur is low in an scale-free network. So it's more resistent to failures than a random graph and than the WS networks, those don't necessarily have hubs."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
